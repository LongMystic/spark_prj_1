{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0999a8bd-265a-44c6-8219-bfee4133d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530b2202-b85e-49a5-ad88-c996be6132a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/05 17:03:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/05 17:03:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"spark_query\")\n",
    "    .config(\"spark.jars\", \"/home/long.vk@citigo.id/Downloads/mysql-connector-j-8.0.33.jar\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271900c4-c45f-4f2e-97df-e1466b02f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"jdbc:mysql://localhost:3306\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"password\",\n",
    "    \"driver\": \"com.mysql.jdbc.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0fc8c1-b5b8-4f7e-9a89-1885e13d8e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.\n"
     ]
    }
   ],
   "source": [
    "df_acc_creation = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\", f\"{url}/spark_prj_1_sample_dw\")\n",
    "    .option(\"driver\", properties[\"driver\"])\n",
    "    .option(\"dbtable\", \"account_creation_fact\")\n",
    "    .option(\"user\", properties[\"user\"])\n",
    "    .option(\"password\", properties[\"password\"])\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060f2ddc-bd06-4d19-b8ff-9a487c9aaa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+\n",
      "|acc_id|user_id|created_date|\n",
      "+------+-------+------------+\n",
      "|     1|      1|  2023-06-20|\n",
      "|     2|      1|  2022-02-01|\n",
      "|     3|      2|  2018-08-01|\n",
      "|     4|      2|  2018-11-09|\n",
      "|     5|      2|  2024-03-14|\n",
      "+------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_acc_creation.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba33d77-7357-4abb-9129-255ae2ab886e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000992"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_creation.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "553049c1-bbc1-473b-8f85-696e3348a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_creation.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac282990-e2f6-40bf-bc5d-0302d7a6097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|number_of_account|\n",
      "+-----------------+\n",
      "|           178741|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) AS number_of_account\n",
    "    FROM df\n",
    "    WHERE df.created_date > '2024-01-01'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741c8497-d251-42f4-bc64-a6804e4866c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\", f\"{url}/spark_prj_1_sample_dw\")\n",
    "    .option(\"driver\", properties[\"driver\"])\n",
    "    .option(\"dbtable\", \"account_dim\")\n",
    "    .option(\"user\", properties[\"user\"])\n",
    "    .option(\"password\", properties[\"password\"])\n",
    "    .load()\n",
    ").createOrReplaceTempView(\"account_dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8468d1b-4616-4846-9f61-20e1e6c4041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\", f\"{url}/spark_prj_1_sample_dw\")\n",
    "    .option(\"driver\", properties[\"driver\"])\n",
    "    .option(\"dbtable\", \"user_dim\")\n",
    "    .option(\"user\", properties[\"user\"])\n",
    "    .option(\"password\", properties[\"password\"])\n",
    "    .load()\n",
    ").createOrReplaceTempView(\"user_dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cd4d8fa-3e66-4912-82a4-3dcd04db1667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                       (0 + 12) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+-----------------+\n",
      "|user_id|       full_name|number_of_account|\n",
      "+-------+----------------+-----------------+\n",
      "|      1|     Paul Wright|                2|\n",
      "|      2|      Ruth James|                4|\n",
      "|      3| Fernando Pineda|                3|\n",
      "|      4|Christopher Webb|                0|\n",
      "|      5|    Joseph Scott|                2|\n",
      "|      6|    Candice Snow|                0|\n",
      "|      7|   David Hawkins|                3|\n",
      "|      8| Jennifer Harper|                4|\n",
      "|      9|     Sonya Blake|                3|\n",
      "|     10|      Mary Garza|                3|\n",
      "|     11|   Jessica Brown|                3|\n",
      "|     12|    James Malone|                2|\n",
      "|     13|  Jessica Gordon|                0|\n",
      "|     14|      David Lane|                2|\n",
      "|     15| Tiffany Anthony|                4|\n",
      "|     16|    Terri Mathis|                3|\n",
      "|     17| William Watkins|                1|\n",
      "|     18|    Bruce Taylor|                2|\n",
      "|     19|    Tamara Ortiz|                3|\n",
      "|     20|  Shawn Castillo|                4|\n",
      "+-------+----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "            ud.user_id,\n",
    "            CONCAT(first_name, ' ', last_name) as full_name,\n",
    "            number_of_account\n",
    "    FROM user_dim as ud\n",
    "    JOIN (\n",
    "        SELECT ud.user_id,\n",
    "               COALESCE(COUNT(df.user_id), 0) AS number_of_account\n",
    "        FROM user_dim ud\n",
    "        LEFT JOIN df ON ud.user_id = df.user_id\n",
    "        GROUP BY ud.user_id\n",
    "        ORDER BY ud.user_id\n",
    "    ) as tmp\n",
    "    ON ud.user_id = tmp.user_id\n",
    "    ORDER BY ud.user_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a1864d8-fc0d-45d0-9989-0277b4afdb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|number_of_account|          avg(age)|\n",
      "+-----------------+------------------+\n",
      "|                1|42.523720018796055|\n",
      "|                3|42.506787285185666|\n",
      "|                2|42.525144737766276|\n",
      "|                4|42.536154418706886|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        number_of_account, AVG(age)\n",
    "    FROM user_dim ud\n",
    "    JOIN (\n",
    "        SELECT df.user_id,\n",
    "                count(df.user_id) as number_of_account\n",
    "        FROM df\n",
    "        GROUP BY df.user_id\n",
    "    ) as tmp\n",
    "    ON ud.user_id = tmp.user_id\n",
    "    GROUP BY number_of_account\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3e92172-db65-403c-95e8-0e965fb7589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 116:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         avg(age)|\n",
      "+-----------------+\n",
      "|42.52145842951798|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        AVG(age)\n",
    "    FROM user_dim ud\n",
    "    JOIN (\n",
    "        SELECT df.user_id,\n",
    "                count(df.user_id) as number_of_account\n",
    "        FROM df\n",
    "        GROUP BY df.user_id\n",
    "        HAVING number_of_account > 2\n",
    "    ) as tmp\n",
    "    ON ud.user_id = tmp.user_id\n",
    "    WHERE age > 0\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f7c68-f596-4015-8f08-dc51a6f62775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
